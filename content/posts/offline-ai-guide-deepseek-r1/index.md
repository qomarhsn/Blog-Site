---
title: "সম্পূর্ণ অফলাইনে নিজ লোকাল ডিভাইসে (ফোন/পিসি) ব্যবহার করুন এআই"
date: 2025-05-20T00:00:00+06:00
categories:
  - Technology

tags:
  - Linux
  - Windows
  - MacOS
  - Privacy
  - Mobile Tips
  - AI
  - Artificial Intiligenc
  - 

resources:
  - name: featured-image
    src: featured.webp
  - name: featured-image-preview
    src: featured.webp

comments: true
---

বর্তমানে এয়াইয়ের মাধ্যমে খোঁজাখুঁজি অনেকটাই সহজ হয়ে গেছে। ছোটখাটো যে কোনো প্রশ্নের উত্তর গুগল বা অন্যান্য সার্চ ইঞ্জিনের বদলে সরাসরি এআই থেকে পাওয়া যায়। তবে জনপ্রিয় অনেক এআই মডেলই সার্ভার-ভিত্তিক হওয়ায় এগুলো অফলাইনে ব্যবহার করা যায় না। কিন্তু বাজারে রয়েছে কিছু সম্পূর্ণ ফ্রি ও শক্তিশালী এআই মডেল, যেগুলোকে আপনি আপনার মোবাইল বা কম্পিউটারে ডাউনলোড করে অফলাইনে চালাতে পারবেন।

এর মধ্যে অন্যতম হল **DeepSeek R1**—কিছু ক্ষেত্রে ChatGPT থেকেও ভালো ফলাফল দিতে সক্ষম। এই পোস্টে আমরা দেখব, কীভাবে অ্যান্ড্রয়েড কিংবা পিসিতে (লিনাক্স, Windows, MacOS) DeepSeek R1 মোডেলটি চালু করবেন।

---

## প্রথম স্টেপ: Ollama ইনস্টল করা

Ollama হচ্ছে এক ধরনের লোকাল এআই রানটাইম, যার মাধ্যমে ডিভাইসে এআই মডেল ডাউনলোড ও ব্যবহার করা যায়। 

### লিনাক্সের জন্য

টার্মিনালে নিচের কমান্ড রান করুন:

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### উইন্ডোজ / ম্যাক

১. [https://ollama.com/download](https://ollama.com/download) থেকে আপনার অপারেটিং সিস্টেম নির্বাচন করে ইনস্টলার ডাউনলোড করুন।
২. অএস এর ইন্সটলেশন সিস্টেম ফলো করে ইন্সটল করে নিন। 

### অ্যান্ড্রয়েডের জন্য (Termux)

1. F-Droid থেকে [Termux](   https://f-droid.org/packages/com.termux/
) ইন্সটল করুন:

2. Termux ওপেন করে নিচের কমান্ডটি দিয়ে স্টোরেজ পার্মিশন দিন:

   ```bash
   termux-setup-storage
   ```
3. প্যাকেজ আপডেট ও আপগ্রেড করুন:

   ```bash
   pkg update && pkg upgrade
   ```
4. Ollama ইন্সটল করুন:

   ```bash
   pkg install ollama
   ```
5. Ollama সার্ভার রান করুন:

   ```bash
   ollama serve &
   ```

---

## দ্বিতীয় স্টেপ: DeepSeek R1 মডেল বেছে নিন ও ইনস্টল করুন

DeepSeek R1 মডেলের বিভিন্ন সাইজ আপনার ডিভাইসের সক্ষমতার ওপর নির্ভর করে নির্বাচন করুন। নিচে মূল মডেলগুলো ও ইনস্টলেশন কমান্ডের তালিকা দেওয়া হলো:

| মডেল নাম             | সাইজ  | Context | ইনস্টল কমান্ড                   |
| -------------------- | ----- | ------- | ------------------------------- |
| `deepseek-r1:latest` | 4.7GB | 128K    | `ollama run deepseek-r1:latest` |
| `deepseek-r1:1.5b`   | 1.1GB | 128K    | `ollama run deepseek-r1:1.5b`   |
| `deepseek-r1:7b`     | 4.7GB | 128K    | `ollama run deepseek-r1:7b`     |
| `deepseek-r1:8b`     | 4.9GB | 128K    | `ollama run deepseek-r1:8b`     |
| `deepseek-r1:14b`    | 9.0GB | 128K    | `ollama run deepseek-r1:14b`    |
| `deepseek-r1:32b`    | 20GB  | 128K    | `ollama run deepseek-r1:32b`    |
| `deepseek-r1:70b`    | 43GB  | 128K    | `ollama run deepseek-r1:70b`    |
| `deepseek-r1:671b`   | 404GB | 160K    | `ollama run deepseek-r1:671b`   |

> **নোট:** আপনার ডিভাইসের র‍্যাম ও ডিস্ক স্পেস অনুযায়ী উপযুক্ত মডেল বাছাই করুন।

**উদাহরণ:** আমি আপাতত সবচেয়ে ছোট মডেল `deepseek-r1:1.5b` বেছে নিয়েছি। করার জন্য টার্মিনালে কমান্ড দিন:

```bash
ollama run deepseek-r1:1.5b
```

ডাউনলোড হওয়ার পর একই কমান্ড দিয়ে এআই মডেল চালু করতে হবে।

এবার টার্মিনাল থেকেই এআই ইউজ করতে পারবেন, তবে GUI এর মাধ্যমে বেস্ট ইউজার এক্সপেরিয়েন্স পাওয়ার জন্য পরবর্তী ধাপে GUI ইন্সটল করব।

---

## তৃতীয় স্টেপ: Podman দিয়ে Web UI সেটআপ করুন

টার্মিনালে এআই চালানোটি সব সময়ই স্বাচ্ছন্দ্যদায়ক হয় না; তাই Web UI (ওপেন-ওয়েব-ইউআই) সেটআপ করলে ব্যবহার অনেক সহজ হয়ে যাবে।

### পিসিতে Podman ইন্সটল

**লিনাক্স (ডিস্ট্রো অনুযায়ী):**

* আর্চ:

  ```bash
  sudo pacman -S podman
  ```
* ফেডোরা:

  ```bash
  sudo dnf -y install podman
  ```
* উবুন্টু/ডেবিয়ান:

  ```bash
  sudo apt-get -y install podman
  ```

**উইন্ডোজ / ম্যাক**
Podman এর অফিসিয়াল সাইটে ([https://podman.io/getting-started/installation](https://podman.io/getting-started/installation)) আপনার OS নির্বাচন করে নির্দেশনা অনুসরণ করুন।

### Open-WebUI কনটেইনার চালু করা

Open-WebUI কনটেইনার চালু করার জন্য টার্মিনালে কমান্ড দিন। এটি স্বয়ংক্রিয়ভাবে ডাউনলড ও সেটআপ কমপ্লিট করবে। 

```bash
podman run -d \
  -p 3000:8080 \
  --add-host=host.docker.internal:host-gateway \
  -v open-webui:/app/backend/data \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:main
```

1. ব্রাউজারে : `http://localhost:3000` ভিজিট করলেই চ্যাট জিপিটির মত আকর্ষণীয় ইউআই দেখতে পাবেন। 
2. এবার ইউআই এর সেটিংসে API হিসাবে “Custom API” নির্বাচন করুন।
3. API URL দিন: `http://localhost:11434`

> **জিপিইউ এক্সিলারেশন:** আপনার পিসিতে যদি GPU থাকে, তাহলে Open-WebUI এর অফিসিয়াল ডকুমেন্টেশন থেকে GPU সাপোর্টেড ইমেজ ও রান কমান্ড ব্যবহার করুন।

### অ্যান্ড্রয়েডে Web UI

অ্যান্ড্রয়েডেও Podman সরাসরি চালানো একটু জটিল; তাই ওপেন-ওয়েব-ইউআই অ্যাপ বা ওয়েবভার্সন ব্রাউজারেই চালাতে পারেন:

1. Ollama সার্ভার চালু রাখুন (`ollama serve &`)।
2. **Termux**-এ টার্মিনাল থেকে পোর্ট ফরওয়ার্ডিং করুন (উদাহরণ):

   ```bash
   termux-forward 8080 3000
   ```
3. ফোনের ব্রাউজারে যান: `http://localhost:3000`
4. উপরের মতো API সেটিংস করুন: `http://localhost:11434`

---

## ব্যবহারে যাত্রা শুরু করুন!

এবার আপনি সম্পূর্ণ **অফলাইনে** আপনার ডিভাইসে DeepSeek R1 মডেল ব্যবহার করতে প্রস্তুত। যেকোনো প্রশ্নের উত্তর পেতে ব্রাউজার-ভিত্তিক সহজ ইন্টারফেস কিংবা সরাসরি টার্মিনাল—দুই দিক থেকেই চেষ্টা করে দেখুন। আর যদি কোনো সমস্যা দেখেন, নিচে কমেন্ট করুন!